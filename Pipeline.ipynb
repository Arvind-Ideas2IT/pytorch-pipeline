{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "from kfp.components import load_component_from_file, load_component_from_url\n",
    "from kfp import dsl\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [{'created_at': datetime.datetime(2021, 2, 22, 10, 16, 13, tzinfo=tzlocal()),\n",
       "                  'description': None,\n",
       "                  'id': 'bc05a15c-5ac6-4cdf-935b-7a6451089d2c',\n",
       "                  'name': 'sample',\n",
       "                  'resource_references': [{'key': {'id': 'admin',\n",
       "                                                   'type': 'NAMESPACE'},\n",
       "                                           'name': None,\n",
       "                                           'relationship': 'OWNER'}],\n",
       "                  'storage_state': 'STORAGESTATE_AVAILABLE'}],\n",
       " 'next_page_token': None,\n",
       " 'total_size': 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authservice_session='authservice_session=MTYxNDI0NzA4N3xOd3dBTkV0SVVVVkNWVTlPUkZWS04waEVXazVOVjB0SldWVTNXRVpXVGt4VVR6UTBUelJYVlZSVFZFVkhUMGxSV0VKWlRVUXpUVUU9fMZX0CmJhl9c5iSDbK-mRTLJyks0YRYWlMMg6bbde9pc'\n",
    "client = kfp.Client(host='http://ad7fc227388c3431f9c778285d481334-127942271.us-west-2.elb.amazonaws.com/pipeline', cookies=authservice_session)\n",
    "client.list_experiments(namespace=\"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"resnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Model Archiver\n",
      "inputs:\n",
      "- {name: properties, type: String}\n",
      "- {name: extraFiles, type: String, default: \"\"}\n",
      "- {name: modelFile, type: String, default: \"\"}\n",
      "- {name: serializedFile, type: String}\n",
      "- {name: handlerFile, type: String, default: \"\"}\n",
      "- {name: requirementsFile, type: String, default: \"\"}\n",
      "outputs:\n",
      "  - {name: output_directory, type: String}\n",
      "implementation:\n",
      "  container:\n",
      "    image: jagadeeshj/model_archive_step:25-02-2021-13-51-56.943180\n",
      "    command: [\"/usr/local/bin/dockerd-entrypoint.sh\",\n",
      "        \"--output_path\", {outputPath: output_directory},\n",
      "        \"--properties\", {inputValue: properties},\n",
      "        \"--serializedfile\", {inputValue: serializedFile},\n",
      "        \"--handlerfile\", {inputValue: handlerFile},\n",
      "        \"--modelfile\", {inputValue: modelFile},\n",
      "        \"--extrafiles\", {inputValue: extraFiles},\n",
      "        \"--requirements\", {inputValue: requirementsFile}\n",
      "    ]"
     ]
    }
   ],
   "source": [
    "!cat model_archive_step/component.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load components (note the components are not platform specific, but the importers are)\n",
    "data_prep_op = load_component_from_file(f\"data_prep_step/{model}/component.yaml\")\n",
    "train_model_op = load_component_from_file(f\"training_step/{model}/component.yaml\")\n",
    "list_item_op = load_component_from_file(\"file/component.yaml\")\n",
    "download_op = load_component_from_file(\"web/component.yaml\")\n",
    "model_archive_op = load_component_from_file(\"model_archive_step/component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = \"pytorchcnn\"\n",
    ")\n",
    "def train_imagenet_cnn_pytorch(\n",
    "    ):\n",
    "        \n",
    "    # data_prep_task = data_prep_op(input_data = \"\")\n",
    "    # data_prep_task = data_prep_op(input_data = \"gs://cloud-ml-nas-public/classification/imagenet/train*\", vocab_file = \"bert_base_uncased_vocab.txt\", vocab_file_url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\")\n",
    "\n",
    "    # temp_input = \"gs://managed-pipeline-test-bugbash/20210130/pipeline_root/pavel/c14ec128-18d4-4980-b9f3-e1c6f4babb51/pytorchcnn-dj5sg-2878573190/output_data/prefix\"\n",
    "    #data_prep_task.outputs[\"output_data\"])\n",
    "\n",
    "    # train_model_task = (train_model_op(trainingdata = \"\").\n",
    "    #     set_cpu_limit('4').\n",
    "    #     set_memory_limit('14Gi')\n",
    "    # )    \n",
    "    # archive_prep_task = archive_prep_op(folder = train_model_task.outputs[\"modelcheckpoint\"], model_name = \"resnet\")\n",
    "\n",
    "    # train_model_task = (train_model_op(trainingdata = data_prep_task.outputs[\"output_data\"], maxepochs = 2, \n",
    "    #     numsamples = 150, \n",
    "    #     batchsize = 16,\n",
    "    #     numworkers = 2,\n",
    "    #     learningrate = 0.001,\n",
    "    #     accelerator = \"\")\n",
    "    #     .set_cpu_limit('4').\n",
    "    #     set_memory_limit('14Gi')\n",
    "    # )\n",
    "\n",
    "#     prop_task = download_op(url = \"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/properties.json\", input = \"\")\n",
    "#     model_task = download_op(url = \"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/model.py\", input = prop_task.outputs['output'])\n",
    "#     serial_task = download_op(url = \"https://download.pytorch.org/models/resnet18-5c106cde.pth\", input = model_task.outputs['output'])\n",
    "#     extra_task = download_op(url = \"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/index_to_name.json\", input = serial_task.outputs['output'])\n",
    "\n",
    "#     list_item_task = list_item_op(directory = extra_task.outputs[\"output\"])\n",
    "\n",
    "#   Using paths \n",
    "#     model_archive_task = model_archive_op(\n",
    "#         input_directory=extra_task.outputs['output'],\n",
    "#         handlerfile=\"image_classifier\")\n",
    "\n",
    "#     Using files\n",
    "    model_archive_task = model_archive_op(\n",
    "        properties=\"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/properties.json\",\n",
    "        modelfile=\"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/model.py\", \n",
    "        serializedfile=\"https://download.pytorch.org/models/resnet18-5c106cde.pth\", \n",
    "        extrafiles=\"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/model_archive/index_to_name.json\", \n",
    "        handlerfile=\"image_classifier\")\n",
    "\n",
    "\n",
    "    list_item_task = list_item_op(directory = model_archive_task.outputs[\"output_directory\"])\n",
    "\n",
    "#     deploy_model_task = deploy_model_op(\n",
    "#         action = 'create',\n",
    "#         model_name='pytorch',\n",
    "#         default_model_uri='gs://kfserving-samples/models/pytorch/cifar10/',\n",
    "#         namespace='admin',\n",
    "#         framework='pytorch',\n",
    "#         default_custom_model_spec='{}',\n",
    "#         canary_custom_model_spec='{}',\n",
    "#         autoscaling_target='0',\n",
    "#         kfserving_endpoint=''\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://ad7fc227388c3431f9c778285d481334-127942271.us-west-2.elb.amazonaws.com/pipeline/#/runs/details/4ccebc59-70ce-426b-9659-5f8c35c3700e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compiler.Compiler().compile(train_imagenet_cnn_pytorch, 'pytorch.tar.gz', type_check=True)\n",
    "# Execute pipeline\n",
    "run = client.run_pipeline(\"bc05a15c-5ac6-4cdf-935b-7a6451089d2c\", 'pytorch-model', 'pytorch.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
